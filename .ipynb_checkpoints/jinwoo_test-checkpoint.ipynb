{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e375652e-bbb0-4486-89e5-8718ca49c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from ssl_utils import train_ssl\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eb4b428-c362-4fc5-84d2-32378cec92e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total GPU count: 3\n",
      "current working GPU index: 2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu') \n",
    "# option: cuda:0 cuda:1 cuda:2\n",
    "print(f'total GPU count: {torch.cuda.device_count()}')\n",
    "print(f'current working GPU index: {device.index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "195f4c63-e26e-42b1-b00b-d46b333099b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMCDataProcessor:\n",
    "    def __init__(self, base_directory):\n",
    "        self.base_directory = base_directory\n",
    "        \n",
    "    def extract_patient_id(self, file_name, ring_type):\n",
    "        if ring_type in ['rk4', 'rw3']:\n",
    "            return file_name.split('_')[2][-3:]\n",
    "        elif ring_type in ['rs4', 'rw4', 'w4', 'w5', 'w7', 'w56']:\n",
    "            return file_name.split('_')[1][-3:]\n",
    "        elif ring_type == 'rw2':\n",
    "            return file_name.split('_')[0][-3:]\n",
    "        else:\n",
    "            return file_name.split('_')[2][-3:]\n",
    "    \n",
    "    def load_ring_data(self, ring_types):\n",
    "        add_folder = os.path.join(self.base_directory, 'add')\n",
    "        \n",
    "        ring_data = []\n",
    "        \n",
    "        for ring_type in ring_types:\n",
    "            ring_path = os.path.join(add_folder, f'apnea_algo_input_{ring_type}')\n",
    "            print(ring_path)\n",
    "            if not os.path.exists(ring_path):\n",
    "                continue\n",
    "                \n",
    "            csv_files = [f for f in os.listdir(ring_path) if f.endswith('.csv')]\n",
    "            \n",
    "            for file_name in csv_files:\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(os.path.join(ring_path, file_name))\n",
    "                    patient_id = self.extract_patient_id(file_name, ring_type)\n",
    "                    \n",
    "                    features = {}\n",
    "                    if 'SpO2' in df.columns:\n",
    "                        features['SpO2'] = df['SpO2'].values\n",
    "                    if 'HR' in df.columns:\n",
    "                        features['HR'] = df['HR'].values\n",
    "                    if 'acc_power' in df.columns:\n",
    "                        features['acc_power'] = df['acc_power'].values\n",
    "                    if 'DC_R' in df.columns:\n",
    "                        features['DC_R'] = df['DC_R'].values\n",
    "                        \n",
    "                    ring_data.append((features, f\"{ring_type}_{patient_id}\"))\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                    \n",
    "        return ring_data\n",
    "    \n",
    "    def load_watch_unlabeled_data(self, watch_types):\n",
    "        add_folder = os.path.join(self.base_directory, 'add')\n",
    "        watch_data = []\n",
    "        \n",
    "        for watch_type in watch_types:\n",
    "            watch_path = os.path.join(add_folder, f'apnea_algo_input_{watch_type}')\n",
    "            if not os.path.exists(watch_path):\n",
    "                continue\n",
    "                \n",
    "            csv_files = [f for f in os.listdir(watch_path) if f.endswith('.csv')]\n",
    "            \n",
    "            for file_name in csv_files:\n",
    "                try:\n",
    "                    df = pd.read_csv(os.path.join(watch_path, file_name))\n",
    "                    patient_id = self.extract_patient_id(file_name, watch_type)\n",
    "                    \n",
    "                    features = {}\n",
    "                    if 'SpO2' in df.columns:\n",
    "                        features['SpO2'] = df['SpO2'].values\n",
    "                    if 'HR' in df.columns:\n",
    "                        features['HR'] = df['HR'].values\n",
    "                    if 'acc_power' in df.columns:\n",
    "                        features['acc_power'] = df['acc_power'].values\n",
    "                    if 'DC_R' in df.columns:\n",
    "                        features['DC_R'] = df['DC_R'].values\n",
    "                        \n",
    "                    watch_data.append((features, f\"{watch_type}_{patient_id}\"))\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                    \n",
    "        return watch_data\n",
    "    \n",
    "    def load_watch_labeled_data(self):\n",
    "        watch_data = []\n",
    "        device_names = ['GW4', 'GW5', 'GW6', 'GW7']\n",
    "        \n",
    "        for device_name in device_names:\n",
    "            path = os.path.join(self.base_directory, f'watch{device_name[-1]}', 'apnea_algo_input')\n",
    "            if not os.path.exists(path):\n",
    "                continue\n",
    "                \n",
    "            csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "            \n",
    "            for file_name in csv_files:\n",
    "                try:\n",
    "                    df = pd.read_csv(os.path.join(path, file_name))\n",
    "                    \n",
    "                    if device_name == 'GW4':\n",
    "                        patient = 'GW4' + file_name.split('SUB_SMC_')[1].split('_')[0]\n",
    "                    else:\n",
    "                        patient_id = file_name.split('_Id')[1].split('_')[0]\n",
    "                        patient = 'GW' + device_name[-1] + patient_id[-3:]\n",
    "                    \n",
    "                    features = {}\n",
    "                    if 'SpO2' in df.columns:\n",
    "                        features['SpO2'] = df['SpO2'].values\n",
    "                    if 'HR' in df.columns:\n",
    "                        features['HR'] = df['HR'].values\n",
    "                    if 'acc_power' in df.columns:\n",
    "                        features['acc_power'] = df['acc_power'].values\n",
    "                    if 'DC_R' in df.columns:\n",
    "                        features['DC_R'] = df['DC_R'].values\n",
    "                        \n",
    "                    watch_data.append((features, patient))\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                    \n",
    "        return watch_data\n",
    "    \n",
    "    def interpolate_missing_values(self, signal):\n",
    "        result = signal.copy()\n",
    "        zero_indices = np.where(signal == 0)[0]\n",
    "        \n",
    "        for idx in zero_indices:\n",
    "            left_val = None\n",
    "            right_val = None\n",
    "            \n",
    "            for i in range(idx-1, -1, -1):\n",
    "                if signal[i] != 0:\n",
    "                    left_val = signal[i]\n",
    "                    left_idx = i\n",
    "                    break\n",
    "            \n",
    "            for i in range(idx+1, len(signal)):\n",
    "                if signal[i] != 0:\n",
    "                    right_val = signal[i]\n",
    "                    right_idx = i\n",
    "                    break\n",
    "            \n",
    "            if left_val is not None and right_val is not None:\n",
    "                weight = (idx - left_idx) / (right_idx - left_idx)\n",
    "                result[idx] = left_val + weight * (right_val - left_val)\n",
    "            elif left_val is not None:\n",
    "                result[idx] = left_val\n",
    "            elif right_val is not None:\n",
    "                result[idx] = right_val\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def normalize_signal(self, signal):\n",
    "        scaler = MinMaxScaler()\n",
    "        return scaler.fit_transform(signal.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    def preprocess_data(self, data_list, feature_names, segment_length=1000):\n",
    "        processed_segments = []\n",
    "        \n",
    "        for features_dict, patient_id in data_list:\n",
    "            feature_arrays = []\n",
    "            min_length = float('inf')\n",
    "            \n",
    "            for feature_name in feature_names:\n",
    "                if feature_name in features_dict:\n",
    "                    feature_arrays.append(features_dict[feature_name])\n",
    "                    min_length = min(min_length, len(features_dict[feature_name]))\n",
    "                else:\n",
    "                    print(f\"Warning: {feature_name} not found for {patient_id}\")\n",
    "                    continue\n",
    "            \n",
    "            if len(feature_arrays) != len(feature_names):\n",
    "                continue\n",
    "                \n",
    "            feature_arrays = [arr[:min_length] for arr in feature_arrays]\n",
    "            \n",
    "            processed_features = []\n",
    "            for arr in feature_arrays:\n",
    "                interpolated = self.interpolate_missing_values(arr)\n",
    "                normalized = self.normalize_signal(interpolated)\n",
    "                processed_features.append(normalized)\n",
    "            \n",
    "            num_segments = min_length // segment_length\n",
    "            for i in range(num_segments):\n",
    "                start_idx = i * segment_length\n",
    "                end_idx = start_idx + segment_length\n",
    "                \n",
    "                segment_features = []\n",
    "                zero_percentage_total = 0\n",
    "                \n",
    "                for feature_arr in feature_arrays:\n",
    "                    segment = feature_arr[start_idx:end_idx]\n",
    "                    zero_count = np.sum(segment == 0)\n",
    "                    zero_percentage_total += zero_count / len(segment)\n",
    "                    \n",
    "                    processed_segment = processed_features[len(segment_features)][start_idx:end_idx]\n",
    "                    segment_features.append(processed_segment)\n",
    "                \n",
    "                avg_zero_percentage = zero_percentage_total / len(feature_arrays)\n",
    "                if avg_zero_percentage <= 0.5:\n",
    "                    multi_channel_segment = np.stack(segment_features, axis=0)\n",
    "                    processed_segments.append((multi_channel_segment, f\"{patient_id}_seg{i}\"))\n",
    "        \n",
    "        return processed_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc64812f-b118-48f8-b873-db49a30db627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SMC SSL Training Pipeline ===\n",
      "\n",
      "1. Loading data...\n",
      "SMC_WatchSpO2_deliverable_250918/SMC_WatchSpO2_deliverable_241226/add/apnea_algo_input_rk4\n",
      "SMC_WatchSpO2_deliverable_250918/SMC_WatchSpO2_deliverable_241226/add/apnea_algo_input_rs4\n",
      "SMC_WatchSpO2_deliverable_250918/SMC_WatchSpO2_deliverable_241226/add/apnea_algo_input_rw2\n",
      "SMC_WatchSpO2_deliverable_250918/SMC_WatchSpO2_deliverable_241226/add/apnea_algo_input_rw3\n",
      "SMC_WatchSpO2_deliverable_250918/SMC_WatchSpO2_deliverable_241226/add/apnea_algo_input_rw4\n",
      "Ring data: 536 samples\n",
      "Watch unlabeled: 790 samples\n",
      "Watch labeled: 580 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# base_directory = r\"C:\\Users\\PC\\ssl\\ssl_new\\SMC_WatchSpO2_deliverable_250918\\SMC_WatchSpO2_deliverable_241226\"\n",
    "base_directory=r\"SMC_WatchSpO2_deliverable_250918/SMC_WatchSpO2_deliverable_241226\"\n",
    "\n",
    "processor = SMCDataProcessor(base_directory)\n",
    "\n",
    "print(\"=== SMC SSL Training Pipeline ===\")\n",
    "\n",
    "print(\"\\n1. Loading data...\")\n",
    "ring_data = processor.load_ring_data(['rk4', 'rs4', 'rw2', 'rw3', 'rw4'])\n",
    "watch_unlabeled = processor.load_watch_unlabeled_data(['w4', 'w5', 'w56', 'w7'])\n",
    "watch_labeled = processor.load_watch_labeled_data()\n",
    "\n",
    "print(f\"Ring data: {len(ring_data)} samples\")\n",
    "print(f\"Watch unlabeled: {len(watch_unlabeled)} samples\")\n",
    "print(f\"Watch labeled: {len(watch_labeled)} samples\")\n",
    "\n",
    "tasks = {\n",
    "    'Task1': {'features': ['SpO2', 'HR', 'acc_power'], 'data': 'watch_only'}\n",
    "\n",
    "}\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c341446-ca18-4eba-a6ab-f6aa510df6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Task1: ['SpO2', 'HR', 'acc_power'] ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     combined_data \u001b[38;5;241m=\u001b[39m watch_unlabeled \u001b[38;5;241m+\u001b[39m watch_labeled \u001b[38;5;241m+\u001b[39m ring_data\n\u001b[0;32m----> 9\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mpreprocess_data(combined_data, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(processed_data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 175\u001b[0m, in \u001b[0;36mSMCDataProcessor.preprocess_data\u001b[0;34m(self, data_list, feature_names, segment_length)\u001b[0m\n\u001b[1;32m    173\u001b[0m processed_features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m feature_arrays:\n\u001b[0;32m--> 175\u001b[0m     interpolated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolate_missing_values(arr)\n\u001b[1;32m    176\u001b[0m     normalized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_signal(interpolated)\n\u001b[1;32m    177\u001b[0m     processed_features\u001b[38;5;241m.\u001b[39mappend(normalized)\n",
      "Cell \u001b[0;32mIn[8], line 134\u001b[0m, in \u001b[0;36mSMCDataProcessor.interpolate_missing_values\u001b[0;34m(self, signal)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(signal)):\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m signal[i] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m         right_val \u001b[38;5;241m=\u001b[39m signal[i]\n\u001b[1;32m    136\u001b[0m         right_idx \u001b[38;5;241m=\u001b[39m i\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for task_name, config in tasks.items():\n",
    "    print(f\"\\n=== {task_name}: {config['features']} ===\")\n",
    "    \n",
    "    if config['data'] == 'watch_only':\n",
    "        combined_data = watch_unlabeled + watch_labeled\n",
    "    else:\n",
    "        combined_data = watch_unlabeled + watch_labeled + ring_data\n",
    "    \n",
    "    processed_data = processor.preprocess_data(combined_data, config['features'])\n",
    "    \n",
    "    if len(processed_data) == 0:\n",
    "        print(f\"No valid data for {task_name}\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processed segments: {len(processed_data)}\")\n",
    "    \n",
    "    signals = [signal for signal, _ in processed_data]\n",
    "    input_dim = len(config['features'])\n",
    "    \n",
    "    print(f\"Input dimensions: {input_dim}\")\n",
    "    print(f\"Signal shape: {signals[0].shape}\")\n",
    "    \n",
    "    try:\n",
    "        model_path, training_results = train_ssl(\n",
    "            signals, \n",
    "            input_dim=input_dim,\n",
    "            epochs=200,\n",
    "            task_name=task_name,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        results[task_name] = {\n",
    "            'model_path': model_path,\n",
    "            'training_results': training_results,\n",
    "            'num_segments': len(processed_data),\n",
    "            'input_dim': input_dim\n",
    "        }\n",
    "        \n",
    "        print(f\"{task_name} completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training {task_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n=== Training Summary ===\")\n",
    "for task_name, result in results.items():\n",
    "    print(f\"{task_name}: {result['num_segments']} segments, {result['input_dim']}D input\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88c634-affd-495a-bdcf-52a00730b71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
